import torch
import os

desktop_path = 'C:\\Users\\bellavista\\Desktop\\'
model_path = desktop_path + 'model_state_dict.pth'
scripted_model_path = desktop_path + 'scripted_model.pth'

try:
    # Check if files exist
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Model file not found at {model_path}")
    if not os.path.exists(scripted_model_path):
        raise FileNotFoundError(f"Scripted model file not found at {scripted_model_path}")

    # Define your model architecture (assuming it's a custom model)
    class CustomModel(torch.nn.Module):
        def __init__(self):
            super(CustomModel, self).__init__()
            # Define your model layers here
            self.fc = torch.nn.Linear(128, 10)  # Example layer

        def forward(self, x):
            # Define your forward pass here
            x = torch.relu(self.fc(x))
            return x

    # Load state dictionary into a model instance
    model = CustomModel()
    state_dict = torch.load(model_path, map_location=torch.device('cpu'))
    model.load_state_dict(state_dict)
    model.eval()

    # Load scripted model
    try:
        scripted_model = torch.jit.load(scripted_model_path, map_location='cpu')
        scripted_model.eval()
    except RuntimeError as e:
        print(f"Warning: Could not load scripted model - {e}")
        scripted_model = None

    # Test loaded models
    x = torch.randn((1, 128))  # Input shape should match your model's input
    with torch.no_grad():
        out = model(x)
        print("Loaded model output shape:", out.shape)

        if scripted_model is not None:
            out_scripted = scripted_model(x)
            print("Scripted model output shape:", out_scripted.shape)

except Exception as e:
    print(f"Error loading model: {e}")
